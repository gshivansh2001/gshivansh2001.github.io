<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> What Really Happens When You Add Covariates to SDID in Stata | Shivansh Gupta </title> <meta name="author" content="Shivansh Gupta"> <meta name="description" content="A researcher’s walkthrough on understanding covariates in synthetic difference-in-differences"> <meta name="keywords" content="academic-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://gshivansh2001.github.io/blog/2025/sdidI/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Shivansh Gupta </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Research </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/books/">Beyond Research </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">What Really Happens When You Add Covariates to SDID in Stata</h1> <p class="post-meta"> Created on February 14, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>A few days ago, while working on an analysis for a project, I found myself stuck on a deceptively simple question: <strong>what exactly happens when we add covariates to a Synthetic Difference-in-Differences (SDID) model in Stata?</strong> I had used SDID before, I had added covariates before, but this was the first time I <em>actually</em> needed to understand how SDID treated them beneath the hood. The more I looked into it, the clearer it became that SDID handles covariates in a way that is <em>very</em> different from OLS or fixed-effects regressions.</p> <p>So I spent a couple of days reading the literature, digging through the Stata help files, and scrolling through Statalist threads where researchers faced the same questions. This post is a summary of that journey — written the way I wish I had found it when I first went searching.</p> <hr> <h4 id="why-this-problem-caught-my-attention">Why This Problem Caught My Attention</h4> <p>One reason I found this problem particularly interesting is that covariates in SDID behave very differently from how we use controls in standard regression frameworks like <code class="language-plaintext highlighter-rouge">reghdfe</code> or <code class="language-plaintext highlighter-rouge">xtreg</code>. In a typical regression, covariates enter the model as explanatory variables whose coefficients we interpret, test, and often use to reason about underlying mechanisms. The regression framework is built around the idea that these coefficients have a meaning of their own.</p> <p>In SDID, however, covariates serve an entirely different purpose. They are not part of the causal narrative, and their coefficients are not designed to be interpreted. Instead, covariates act as tools for <em>cleaning</em> the outcome variable. SDID uses them to strip away predictable variation so that the remaining residual trends are more comparable between treated and control units. The goal is not to estimate how covariates affect the outcome, but to improve the quality of the synthetic counterfactual.</p> <p>Realizing this difference was helpful because it forced me to rethink what covariates <em>do</em> in SDID. They are not contributors to the final ATT estimate; they are part of a preprocessing step that shapes the data SDID uses. Once I internalized that SDID treats covariates as adjustment mechanisms rather than explanatory variables, the rest of the method — and the behavior of <code class="language-plaintext highlighter-rouge">optimized</code> vs. <code class="language-plaintext highlighter-rouge">projected</code> — became much clearer.</p> <hr> <p>When we add covariates to <strong>Synthetic Difference-in-Differences (SDID)</strong>, the intention is not to estimate the causal effect of those covariates. In fact, SDID does not even try to report meaningful covariate coefficients. Instead, covariates are used to <strong>improve the construction of the synthetic control</strong>. They help clean the outcome by explaining predictable variation so that the SDID weights — the unit weights $\omega$ and the time weights $\lambda$ — are chosen using outcomes that have been “purified” of covariate-driven noise.</p> <p>This adjustment happens before the SDID optimization step. And depending on how we residualize the outcome, the process can behave quite differently.</p> <hr> <h4 id="the-residualized-approach">The Residualized Approach</h4> <p>My first stop was the standard, “optimized” method in Stata. The logic behind it is straightforward. Before SDID starts balancing treated and control units, it <em>first</em> regresses the outcome on the covariates:</p> \[\tilde Y_{it} = Y_{it} - X_{it}\hat\beta\] <p>and then uses $\tilde Y_{it}$ — not the raw outcomes — to compute the synthetic weights. This is reminiscent of partialling out covariates before matching. In practice, the procedure works well when covariates behave similarly for treated and control units, but can struggle when they differ sharply. Because the regression that obtains $\hat\beta$ uses <em>all</em> units (treated and untreated), any imbalance between the two groups flows into the residualization step. As a result, this version of SDID often produces covariate coefficients that cannot be replicated by any standard regression.</p> <hr> <h4 id="the-projected-approach">The Projected Approach</h4> <p>Then I discovered the “projected” method — a quieter option hidden in the Stata help file but discussed extensively on Statalist. This method computes $\hat\beta$ using <strong>only the untreated units</strong>. The idea is elegant: if covariates are supposed to explain untreated outcome variation, then only untreated units should inform their relationship with the outcome. Once these coefficients are estimated, residuals are computed and SDID proceeds normally.</p> <p>What surprised me is how different the results can be. In my own replications — and in several Statalist posts — the projected method produced covariate coefficients that aligned perfectly with a simple fixed-effects regression on the untreated sample. The optimized method did not.</p> <p>At that point, the difference made sense: the two methods are solving two different problems. One residualizes using information from <em>everyone</em>; the other uses only <em>controls</em>, preserving the logic of a synthetic control.</p> <hr> <h4 id="a-note-on-joint-estimation-sdidc">A Note on Joint Estimation (SDIDC)</h4> <p>During this process, I also came across a newer method — SDIDC by Hirshberg and Klosin — which estimates the covariate coefficients and the SDID weights jointly rather than separately. This approach avoids some of the pitfalls of residualizing first and weighting later. It’s still new, but it’s a promising direction, especially when covariates strongly overlap with latent trends.</p> <hr> <h4 id="what-actually-changes-when-covariates-enter-the-model">What Actually Changes When Covariates Enter the Model</h4> <p>One of the most important insights I gained is that <strong>covariates do not change the structure of the SDID estimator itself</strong>. The minimization problem is the same. What changes are the data fed into it. Once we residualize the outcome, SDID computes weights based on $\tilde Y_{it}$, so the resulting $\omega$ and $\lambda$ often look different from the no-covariate case. Consequently, the ATT estimate also shifts.</p> <p>Stata stores the covariate coefficients it used inside <code class="language-plaintext highlighter-rouge">e(beta)</code>, but these are not causal effects and should not be interpreted as such. In fact, most covariates end up statistically insignificant — even when the ATT remains highly significant — because significance was never the goal. The covariates are there to improve balance, not to explain outcomes in a causal sense.</p> <hr> <h4 id="using-covariates-in-stata-what-i-learned">Using Covariates in Stata: What I Learned</h4> <p>I went back to Stata and experimented with the two approaches. The commands looked something like this:</p> <div class="language-stata highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sdid</span><span class="w"> </span><span class="n">outcome</span><span class="w"> </span><span class="n">unitid</span><span class="w"> </span><span class="n">time</span><span class="w"> </span><span class="n">treated</span><span class="p">,</span><span class="w"> </span><span class="n">covariates</span><span class="p">(</span><span class="n">age</span><span class="w"> </span><span class="n">income</span><span class="w"> </span><span class="n">x1</span><span class="w"> </span><span class="n">x2</span><span class="p">,</span><span class="w"> </span><span class="n">optimized</span><span class="p">)</span>
</code></pre></div></div> <p>and</p> <div class="language-stata highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sdid</span><span class="w"> </span><span class="n">outcome</span><span class="w"> </span><span class="n">unitid</span><span class="w"> </span><span class="n">time</span><span class="w"> </span><span class="n">treated</span><span class="p">,</span><span class="w"> </span><span class="n">covariates</span><span class="p">(</span><span class="n">age</span><span class="w"> </span><span class="n">income</span><span class="w"> </span><span class="n">x1</span><span class="w"> </span><span class="n">x2</span><span class="p">,</span><span class="w"> </span><span class="n">projected</span><span class="p">)</span>
</code></pre></div></div> <p>The ATT estimates were reasonably close, but the covariate coefficients were completely different — and only the projected version matched the coefficients from:</p> <div class="language-stata highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">egen</span><span class="w"> </span><span class="n">W</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">treated</span><span class="p">),</span><span class="w"> </span><span class="n">by</span><span class="p">(</span><span class="n">unitid</span><span class="p">)</span>

<span class="n">reghdfe</span><span class="w"> </span><span class="n">outcome</span><span class="w"> </span><span class="n">age</span><span class="w"> </span><span class="n">income</span><span class="w"> </span><span class="n">x1</span><span class="w"> </span><span class="n">x2</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="n">W</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">absorb</span><span class="p">(</span><span class="n">unitid</span><span class="w"> </span><span class="n">time</span><span class="p">)</span><span class="w"> </span><span class="n">cluster</span><span class="p">(</span><span class="n">unitid</span><span class="p">)</span>
</code></pre></div></div> <p>Once I understood the logic, the mismatch stopped bothering me. Optimized and projected are not competing versions of the same method; they are solving different residualization problems.</p> <hr> <h4 id="do-covariates-actually-help">Do Covariates Actually Help?</h4> <p>In my own analysis, adding covariates helped reduce noise in pre-treatment trends for the treated units. But it’s not guaranteed. The only reliable way to check is to look at:</p> <ol> <li> <strong>Pre-treatment fit</strong> — do the synthetic and treated paths align more closely?</li> <li> <strong>Weight stability</strong> — do unit weights become more reasonable?</li> <li> <strong>Robustness across residualization methods</strong> — if optimized and projected produce wildly different ATTs, it may signal an identification issue.</li> <li> <strong>Warnings from the optimization</strong> — SDID sometimes struggles to find weights when covariates introduce multicollinearity.</li> </ol> <p>Like everything else in applied econometrics, covariates help when they help — and sometimes they don’t.</p> <hr> <h4 id="a-small-conceptual-example">A Small Conceptual Example</h4> <p>To build intuition, imagine studying how a policy affects student test scores. Covariates like <code class="language-plaintext highlighter-rouge">income</code> or <code class="language-plaintext highlighter-rouge">school_resources</code> explain part of the variation in scores that has nothing to do with the treatment. By removing this predictable variation first, SDID focuses only on aligning the remaining, unexplained trends across treated and control units. If treated schools differ systematically in those covariates, the projected method tends to produce more stable residuals, which leads to more reliable weights.</p> <hr> <h4 id="further-reading">Further Reading</h4> <p>A few resources I found especially helpful:</p> <ul> <li><a href="https://www.aeaweb.org/articles?id=10.1257/aer.20190159" rel="external nofollow noopener" target="_blank">Arkhangelsky et al. (2021), <em>Synthetic Difference-in-Differences</em></a></li> <li>Stata’s official documentation for <code class="language-plaintext highlighter-rouge">sdid</code> </li> <li><a href="https://klosins.github.io/Hirshberg_Klosin_SDIDC.pdf" rel="external nofollow noopener" target="_blank">Hirshberg &amp; Klosin (2024), <em>Synthetic Differences-in-Differences with Covariates</em></a></li> </ul> <hr> <p>If you’re working on SDID analyses of your own, especially with covariates, I hope this saves you a few hours of searching. For me, the trick was simply realizing that covariates in SDID aren’t part of the causal story — they’re part of the <em>cleaning</em> story. Once that clicked, everything else became much clearer.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/pmf/">Proabilistic Matrix Factorization</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/vc/">Variational Calculus</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/rdp/">Rényi DP</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Shivansh Gupta. Last updated: December 25, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> </body> </html>